{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2022 Semester 1\n",
    "\n",
    "## Assignment 1: Naive Bayes Leaner for Adult Database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Name(s):** Lang (Ron) Chen\n",
    "<br>\n",
    "**Student ID(s):** 1181506"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook.\n",
    "\n",
    "## General info\n",
    "\n",
    "<b>Due date</b>: Friday, 8 April 2022 7pm\n",
    "\n",
    "<b>Submission method</b>: Canvas submission\n",
    "\n",
    "<b>Submission materials</b>: This iPython notebook is a template which you will use for your Assignment 1 submission. You need to only submitted the completed copy of this iPython notebook.\n",
    "\n",
    "<b>Late submissions</b>: -10% per day up to 5 days (both weekdays and weekends count). Submissions more than 5 days late will not be accepted (resul in a mark of 0).\n",
    "<ul>\n",
    "    <li>one day late, -1.0;</li>\n",
    "    <li>two days late, -2.0;</li>\n",
    "    <li>three days late, -3.0;</li>\n",
    "    <li>four days late, -4.0;</li>\n",
    "    <li>five days late, -5.0;</li>\n",
    "</ul>\n",
    "\n",
    "<b>Extensions</b>: Students who are demonstrably unable to submit a full solution in time due to medical reasons or other trauma, may apply for an extension.  In these cases, you should email <a href=\"mailto:ni.ding@unimelb.edu.au\">Ni Ding</a> as soon as possible after those circumstances arise. If you attend a GP or other health care service as a result of illness, be sure to provide a Health Professional Report (HPR) form (get it from the Special Consideration section of the Student Portal), you will need this form to be filled out if your illness develops into something that later requires a Special Consideration application to be lodged. You should scan the HPR form and send it with the extension requests.\n",
    "\n",
    "<b>Marks</b>: This assignment will be marked out of 20, and make up 20% of your overall mark for this subject.\n",
    "\n",
    "<b>Materials</b>: Use Jupyter Notebook and Python page on Canvas for information on the basic setup required for this class, including an iPython notebook viewer and the python packages NLTK, Numpy, Scipy, Matplotlib, Scikit-Learn. You can use any Python built-in packages, but do not use any other 3rd party packages; if your iPython notebook doesn't run on the marker's machine, you will lose marks. <b> You should use Python 3</b>.  \n",
    "\n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). You should edit the sections below where requested, but leave the rest of the code as is. You should leave the output from running your code in the iPython notebook you submit, to assist with marking. The amount each section is worth is given in parenthesis after the instructions. \n",
    "\n",
    "You will be marked not only on the correctness of your methods, but also the quality and efficency of your code: in particular, you should be careful to use Python built-in functions and operators when appropriate and pick descriptive variable names that adhere to <a href=\"https://www.python.org/dev/peps/pep-0008/\">Python style requirements</a>. If you think it might be unclear what you are doing, you should comment your code to help the marker make sense of it. We reserve the right to deduct up to 2 marks for unreadable or exessively inefficient code.\n",
    "\n",
    "8 of the marks available for this Project will be assigned to whether the four specified Python functions work in a manner consistent with the materials from COMP30027. Any other implementation will not be directly assessed (except insofar as it is required to make these five functions work correctly).\n",
    "\n",
    "12 of the marks will be assigned to your responses to the questions, in terms of both accuracy and insightfulness. We will be looking for evidence that you have an implementation that allows you to explore the problem, but also that you have thought deeply about the data and the behaviour of the Naive Bayes classifier.\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via Canvas. Minor changes and clarifications will be announced on the discussion board (ED -> Assignments -> A1); we recommend you check it regularly.\n",
    "\n",
    "<b>Academic misconduct</b>: For most people, collaboration will form a natural part of the undertaking of this homework, and we encourge you to discuss it in general terms with other students. However, this ultimately is still an individual task, and so reuse of code or other instances of clear influence will be considered cheating. Please check the <a href=\"https://canvas.lms.unimelb.edu.au/courses/124196/modules#module_662096\">CIS Academic Honesty training</a> for more information. We will be checking submissions for originality and will invoke the University’s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place.\n",
    "\n",
    "**IMPORTANT**\n",
    "\n",
    "Please carefully read and fill out the <b>Authorship Declaration</b> form at the bottom of the page. Failure to fill out this form results in the following deductions: \n",
    "<UL TYPE=”square”>\n",
    "<LI>missing Authorship Declaration at the bottom of the page, -5.0\n",
    "<LI>incomplete or unsigned Authorship Declaration at the bottom of the page, -3.0\n",
    "</UL>\n",
    "**NOTE: COMPLETE AND SUBMIT THIS FILE. YOU SHOULD IMPLEMENT FOUR FUNCTIONS AND INCLUDE YOUR ANSWERS TO THE QUESTIONS IN THIS FILE ONLY. NO OTHER SUBMISSION IS REQUIRED.**\n",
    "\n",
    "**Keep your code clean. Adding proper comments to your code is MANDATORY.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Base code [8 marks]\n",
    "\n",
    "Instructions\n",
    "1. Do **not** shuffle the data set\n",
    "2. Treat the attributes as they are(e.g., do **not** convert numeric attributes to categorical or categorical to numeric). Implement a Naive Bayes classifier with appropriate likelihood function for each attribute.\n",
    "3. You should implement the Naive Bayes classifier from scratch. Do **not** use existing implementations/learning algorithms.\n",
    "4. You CANNOT have more than one train or predict function. Both continuous numeric attributes and categorical ones should be trained in one `train()` function, similarly for the `predict()`.  \n",
    "5. Apart from the instructions in point 3, you may use libraries to help you with data reading, representation, maths or evaluation\n",
    "6. Ensure that all and only required information is printed, as indicated in the final three code cells. Failure to adhere to print the required information will result in **[-1 mark]** per case. *(We don't mind details like you print a list or several numbers -- just make sure the information is displayed so that it's easily accessible)\n",
    "7. You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. \n",
    "8. You should add adequate comments to make your code easily comprehendible.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should prepare the data by reading it from a file and converting it into a useful format for training and testing\n",
    "# and implement 90-10 splitting as specified in the project description.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(df):\n",
    "    \n",
    "    # split full dataframe into two dataframes x (attribute matrix) and y (labels)\n",
    "    x = df[df.columns[:-1]]\n",
    "    y = df[['label']]\n",
    "    \n",
    "    # run train_test_split 'manually' according to specification\n",
    "    cutoff = int(0.9 * len(x))\n",
    "    x_train = x.iloc[0:cutoff]\n",
    "    x_test = x.iloc[cutoff:]\n",
    "    y_train = y.iloc[0:cutoff]\n",
    "    y_test = y.iloc[cutoff:]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFTER MUCH DELIBERATION, IT WAS DECIDED NOT TO ABSTRACT CERTAIN PARTS OF THE CODE INTO FUNCTIONS\n",
    "# IN KEEPING WITH MAXIMISING READABILITY. NAIVE BAYES INVOLVES RATHER COMPLEX DATA STRUCTURES,\n",
    "# AND KEEPING CODE IN 'CHRONOLOGICAL ORDER' UNDER ONE LARGER FUNCTION HAS BEEN DETERMINED TO\n",
    "# PROVIDE BETTER READABILITY. GIVEN THERE ARE ONLY TWO CLASSES, REPEATED CODE IS RATHER MINIMAL.\n",
    "\n",
    "# NOT THAT <100 LINES OF CODE IS A LOT - ESPECIALLY GIVEN MANY ARE COMMENTS\n",
    "\n",
    "\n",
    "# Instructions for reading in file: place file called 'adult.csv' in directory './dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should calculat prior probabilities and likelihoods (conditional probabilities) \n",
    "# from the training data to build a Naive Bayes model\n",
    "\n",
    "# hardcode the columns which contain numerical attributes\n",
    "NUMERIC_ATTRBS = ['age', 'education num', 'hours per week']\n",
    "\n",
    "def train(x_train, y_train):\n",
    "    \n",
    "    # prepare the data - put x and y back together so can divide dataframe by class\n",
    "    train = x_train.copy()\n",
    "    train['label'] = y_train\n",
    "    \n",
    "    train_c1 = train[train['label'] == ' <=50K']\n",
    "    train_c2 = train[train['label'] == ' >50K']\n",
    "\n",
    "    # Create master dictionaries for each class, which will: for prior and numerical attributes store tuples \n",
    "    # containing log likelihood / mean and standard deviation respectively, or for ordinal attributes store \n",
    "    # dictionaries which contain log observed probabilities of each value.\n",
    "    \n",
    "    # for each dictionary/tuple, it will be surrounded by a further tuple with the second tuple value denoting  \n",
    "    # its status as a numerical attribute, ordinal attribute or prior.\n",
    "\n",
    "    c1_dict = dict() # for ' <=50K'\n",
    "    c2_dict = dict() # for ' >50K'\n",
    "    \n",
    "    # store the log prior probabilities as (prior log prob, 'prior')\n",
    "    c1_dict['prior'] = (np.log(len(train_c1) / len(train)), 'prior')\n",
    "    c2_dict['prior'] = (np.log(len(train_c2) / len(train)), 'prior')\n",
    "    \n",
    "    # iterate through the columns (use x_train to ensure the columns are attributes only)\n",
    "    for col in x_train.columns:\n",
    "        \n",
    "        # if iterate to a column that is numeric (by comparing to hardcoded list)\n",
    "        if col in NUMERIC_ATTRBS:\n",
    "            \n",
    "            # Prevent edge case of having '?' in numeric data which would cause np.mean and np.std to fail\n",
    "            # by putting all numeric data values into a new list.\n",
    "            tmp1 = list()\n",
    "            tmp2 = list()\n",
    "            \n",
    "            for i in train_c1[col].index:\n",
    "                if str(train_c1[col][i]).isnumeric(): # only put it in if it's numeric\n",
    "                    tmp1.append(float(train_c1[col][i])) # ensure that the values are floats, not strings\n",
    "                    # ** the problem is that if one value of the column is not numeric, then even numeric \n",
    "                    # values would be read in as strings by pandas, and would cause problems for subsequent phases\n",
    "            \n",
    "            for i in train_c2[col].index:\n",
    "                if str(train_c2[col][i]).isnumeric():\n",
    "                    tmp2.append(float(train_c2[col][i]))\n",
    "             \n",
    "            # store (mean, std) in ((mean, std), 'num')\n",
    "            c1_dict[col] = ((np.mean(tmp1), np.std(tmp1) * np.sqrt(len(tmp1) / (len(tmp1)-1))), 'num')\n",
    "            c2_dict[col] = ((np.mean(tmp2), np.std(tmp2) * np.sqrt(len(tmp2) / (len(tmp2)-1))), 'num')\n",
    "            # as np.std() is /n^0.5, and we typically use unbiased /(n-1)^0.5, thus need to do *[n/(n-1)]^0.5\n",
    "        \n",
    "        # if find a column that is nominal\n",
    "        else:\n",
    "            \n",
    "            # first find the set of all possible attribute values in the training set\n",
    "            attrb_val = set()\n",
    "            for val in train[col].value_counts().index:\n",
    "                attrb_val.add(val)\n",
    "            attrb_val = list(attrb_val)\n",
    "            \n",
    "            # for each value get its log observed probabilities (laplace smoothed alpha = 1)      \n",
    "            tmp1 = dict()\n",
    "            for i in range(len(train_c1[col].value_counts().index)):\n",
    "                # logic: dict[attrb value] = log( (counts_of_this_attribute_value + 1) / (n+p) ) \n",
    "                tmp1[train_c1[col].value_counts().index[i]] = np.log( (train_c1[col].value_counts().values[i] + 1) \n",
    "                                                                     / (len(train_c1)+len(attrb_val)) )\n",
    "            \n",
    "            # for unseen attribute values that exist in train data but are of other class labels\n",
    "            for i in range(len(attrb_val)):\n",
    "                if attrb_val[i] not in train_c1[col].value_counts().index:\n",
    "                    # logic: dict[unseen attrb value] = log(1/(n+p))\n",
    "                    tmp1[attrb_val[i]] = np.log( 1 / (len(train_c1)+len(attrb_val)) )\n",
    "            \n",
    "            # store {value: log cond probability} in ({value: log cond probability}, 'nom')\n",
    "            c1_dict[col] = (tmp1, 'nom')\n",
    "            \n",
    "            \n",
    "            tmp2 = dict()\n",
    "            for i in range(len(train_c2[col].value_counts().index)):\n",
    "                tmp2[train_c2[col].value_counts().index[i]] = np.log( (train_c2[col].value_counts().values[i] + 1) \n",
    "                                                                     / (len(train_c2)+len(attrb_val)) )\n",
    "            for i in range(len(attrb_val)):\n",
    "                if attrb_val[i] not in train_c2[col].value_counts().index:\n",
    "                    tmp2[attrb_val[i]] = np.log(1/(len(train_c2)+len(attrb_val)))\n",
    "                \n",
    "            c2_dict[col] = (tmp2, 'nom')\n",
    "            \n",
    "    \n",
    "    return c1_dict, c2_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict classes for new items in the testing data\n",
    "import random\n",
    "\n",
    "def predict(x_test, c1_dict, c2_dict):\n",
    "    \n",
    "    # re-index the test set to avoid problems when iterating\n",
    "    x_test.index = range(len(x_test))\n",
    "    \n",
    "    # create lists to store final predictions and class probabilities\n",
    "    y_pred = list()\n",
    "    c1_log_prob = list()\n",
    "    c2_log_prob = list()\n",
    "    \n",
    "    for i in range(len(x_test)):\n",
    "        c1 = 0     # sum of log probabilities for ' <=50' (i.e. log relative postier prob)\n",
    "        c2 = 0     # sum of log probabiliteis for ' >50' (i.e. log relative postier prob)\n",
    "        \n",
    "        # add the log prior probabilities\n",
    "        c1 += c1_dict['prior'][0]\n",
    "        c2 += c2_dict['prior'][0]\n",
    "        \n",
    "        for col in x_test.columns:\n",
    "              \n",
    "            if c1_dict[col][1] == 'num': # numeric attributes\n",
    "                \n",
    "                if str(x_test.loc[i][col]).isnumeric():\n",
    "                    mean_c1 = c1_dict[col][0][0] # read mean value\n",
    "                    std_c1 = c1_dict[col][0][1] # read std value\n",
    "                    c1 += np.log(norm_pdf(float(x_test.loc[i][col]), mean_c1, std_c1)) # add log likelihood\n",
    "                    \n",
    "                    mean_c2 = c2_dict[col][0][0] \n",
    "                    std_c2 = c2_dict[col][0][1] \n",
    "                    c2 += np.log(norm_pdf(float(x_test.loc[i][col]), mean_c2, std_c2))\n",
    "            \n",
    "                else: # Skip this numerical attribute for this instance if value is \"?\"\n",
    "                    pass      \n",
    "                \n",
    "            else: # nominal attributes\n",
    "                \n",
    "                if x_test.loc[i][col] in c1_dict[col][0]: \n",
    "                    # just comparing to the c1 prob set is enough because did laplace, so dict keys (unique attribute values) \n",
    "                    # should contain all training set unique attribute values\n",
    "                    c1 += c1_dict[col][0][x_test.loc[i][col]] # add log conditional probability\n",
    "                    c2 += c2_dict[col][0][x_test.loc[i][col]] \n",
    "                    \n",
    "                else: # Skip this attribute for this instance if value has not been seen in training\n",
    "                    pass\n",
    "                    \n",
    "        \n",
    "        # record the sum log probabilities for the two classes for this particular test instance\n",
    "        c1_log_prob.append(c1)\n",
    "        c2_log_prob.append(c2)\n",
    "        \n",
    "        # record the appropriate prediction, based on the sum log probabilities of the two classes \n",
    "        # for this particular test instance\n",
    "        if c1 > c2:\n",
    "            y_pred.append(' <=50K')\n",
    "        elif c1 < c2:\n",
    "            y_pred.append(' >50K')\n",
    "        else: # if equal then randomly allocate based on distribution of prior\n",
    "            y_pred.append(random.choices([' <=50K', ' >50K'], weights = [np.exp(c1_dict['prior'][0]), 1-np.exp(c1_dict['prior'][0])])[0])\n",
    "            \n",
    "    return y_pred, c1_log_prob, c2_log_prob\n",
    "    \n",
    "\n",
    "\n",
    "def norm_pdf(x, mean, std):\n",
    "    \"\"\" Helper function to calculate likelihood based on x value, and normal distribution hyperparameters\n",
    "    mean and standard deviation \"\"\"\n",
    "    \n",
    "    p = (1 / (std * np.sqrt(2 * np.pi))) * np.power(np.exp(1), (-1/2) * np.power((x - mean) / std, 2))\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaliate the prediction performance by comparing your model’s class outputs to ground\n",
    "# truth labels, return and output accuracy, confusion matrix and F1 score.\n",
    "\n",
    "def evaluate(y_pred, y_test):\n",
    "    \n",
    "    # create dataframe for y_pred and y_test\n",
    "    df = pd.DataFrame({'y_pred': y_pred, 'y_test': y_test['label']})\n",
    "    \n",
    "    # calculate the accuracy\n",
    "    accuracy = len(df[df['y_pred'] == df['y_test']])/len(df)\n",
    "    \n",
    "    # calculate tp, tn, fp, fn - assuming ' <=50K' is 'positive value'\n",
    "    tp = len(df[(df['y_pred'] == ' <=50K') & (df['y_test'] == ' <=50K')]) \n",
    "    tn = len(df[(df['y_pred'] == ' >50K') & (df['y_test'] == ' >50K')]) \n",
    "    fp = len(df[(df['y_pred'] == ' <=50K') & (df['y_test'] == ' >50K')]) \n",
    "    fn = len(df[(df['y_pred'] == ' >50K') & (df['y_test'] == ' <=50K')]) \n",
    "    \n",
    "    # build confusion matrix\n",
    "    c_matrix = pd.DataFrame({'Pred <=50K': [tp, fp], 'Pred >50K': [fn, tn]}, \n",
    "                            index = ['Actual <=50K', 'Actual >50K'])\n",
    "    \n",
    "    \n",
    "    # calculate precision, recall and use it to calcualte the F1 score\n",
    "    precision = (tp/len(df))/(tp/len(df)+fp/len(df))\n",
    "    recall = (tp/len(df))/(tp/len(df)+fn/len(df))\n",
    "    F1 = 2*precision*recall/(precision+recall)\n",
    "    \n",
    "    return accuracy, c_matrix, F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "\n",
      "Confusion Matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred &lt;=50K</th>\n",
       "      <th>Pred &gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual &lt;=50K</th>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual &gt;50K</th>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Pred <=50K  Pred >50K\n",
       "Actual <=50K          69          8\n",
       "Actual >50K            6         17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1: 0.9078947368421053\n",
      "\n",
      "\n",
      "Attribute vectors of instances [0, 1, 2]: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>work class</th>\n",
       "      <th>education</th>\n",
       "      <th>education num</th>\n",
       "      <th>marital status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours per week</th>\n",
       "      <th>native country (region)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>?</td>\n",
       "      <td>1st-4th</td>\n",
       "      <td>2</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         work class   education  education num       marital status  \\\n",
       "0   68                  ?     1st-4th              2             Divorced   \n",
       "1   39          State-gov   Bachelors             13        Never-married   \n",
       "2   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "         occupation    relationship    race      sex  hours per week  \\\n",
       "0                 ?   Not-in-family   White   Female              20   \n",
       "1      Adm-clerical   Not-in-family   White     Male              40   \n",
       "2   Exec-managerial         Husband   White     Male              13   \n",
       "\n",
       "  native country (region)   label  \n",
       "0           United-States   <=50K  \n",
       "1           United-States   <=50K  \n",
       "2           United-States   <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of instances (N):  1000\n",
      "Number of attributes (F):  11\n",
      "Number of labels (L):  2\n",
      "\n",
      "\n",
      "Predicted class log-probabilities for instance N-3:  \n",
      "\t <=50K: -20.768165488458912 \n",
      "\t >50K: -19.76217792549845\n",
      "Predicted class ID for instance N-3:   >50K\n",
      "\n",
      "Predicted class log-probabilities for instance N-2:  \n",
      "\t <=50K: -25.310387321914632 \n",
      "\t >50K: -22.803496285083625\n",
      "Predicted class ID for instance N-2:   >50K\n",
      "\n",
      "Predicted class log-probabilities for instance N-1:  \n",
      "\t <=50K: -16.929982096849525 \n",
      "\t >50K: -16.91915916100011\n",
      "Predicted class ID for instance N-1:   >50K\n"
     ]
    }
   ],
   "source": [
    "# This cell should act as your \"main\" function where you call the above functions \n",
    "# on the full ADULT data set, and print the evaluation score. [0.33 marks]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# First, read in the data and apply your NB model to the ADULT data\n",
    "\n",
    "# read in data. DATA MUST BE STORED IN DIRECTORY './dataset'\n",
    "data = pd.read_csv('./dataset/adult.csv')\n",
    "\n",
    "x_train, x_test, y_train, y_test = preprocess(data)\n",
    "\n",
    "c1_dict, c2_dict = train(x_train, y_train)\n",
    "\n",
    "y_pred, c1_log_prob, c2_log_prob = predict(x_test, c1_dict, c2_dict)\n",
    "\n",
    "accuracy, c_matrix, F1 = evaluate(y_pred, y_test)\n",
    "\n",
    "# Second, print the full evaluation results from the evaluate() function\n",
    "\n",
    "# print accuracy\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "display(c_matrix)\n",
    "\n",
    "# print F1\n",
    "print(\"\\nF1:\", F1)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Third, print data statistics and model predictions, as instructed below \n",
    "# N is the total number of instances, F the total number of attributes, L the total number of labels\n",
    "# The \"class probabilities\" may be unnormalized\n",
    "# The \"predicted class ID\" must be in range (0, L)\n",
    "\n",
    "\n",
    "print(\"Attribute vectors of instances [0, 1, 2]: \") # of the first three records in adult.csv\n",
    "display(data.iloc[0:3, :])\n",
    "\n",
    "print(\"\\nNumber of instances (N): \", len(data))\n",
    "print(\"Number of attributes (F): \", len(data.columns)-1) # exclude the label column\n",
    "print(\"Number of labels (L): \", len(set(data['label'])))\n",
    "\n",
    "# print out the prediction results of the last three instances\n",
    "print(\"\\n\\nPredicted class log-probabilities for instance N-3: \", \"\\n\\t <=50K:\", c1_log_prob[-3], \n",
    "      \"\\n\\t >50K:\", c2_log_prob[-3])\n",
    "print(\"Predicted class ID for instance N-3: \", y_pred[-3])\n",
    "print(\"\\nPredicted class log-probabilities for instance N-2: \", \"\\n\\t <=50K:\", c1_log_prob[-2], \n",
    "      \"\\n\\t >50K:\", c2_log_prob[-2])\n",
    "print(\"Predicted class ID for instance N-2: \", y_pred[-2])\n",
    "print(\"\\nPredicted class log-probabilities for instance N-1: \", \"\\n\\t <=50K:\", c1_log_prob[-1], \n",
    "      \"\\n\\t >50K:\", c2_log_prob[-1])\n",
    "print(\"Predicted class ID for instance N-1: \", y_pred[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Conceptual questions [8 marks for groups of 1] / [16 marks for groups of 2]\n",
    "\n",
    "\n",
    "If you are in a group of 1, you should respond to Q1 and Q2.\n",
    "\n",
    "If you are in a group of 2, you should respond to Q1, Q2, Q3 and Q4.\n",
    "\n",
    "A response to a question should take about 100–250 words. You may need to develope codes or functions to help respond to the question here. \n",
    "\n",
    "#### NOTE: We strongly recommend <u>including figures or tables, etc.</u> to support your responses. The figures and tables inserted in Markdown cells must be reproducable by your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 [4 marks]\n",
    "<u>Sensitivity</u> and <u>specificity</u> are two model evaluation metrics.  A good model should have both sensitivity and specificity high. Use the $2 \\times 2$ confusion matrix returned by `evaluate()` to calculate the sensitivity and specificity. Do you see a difference between them? If so, what causes this difference? Provide suggestions to improve the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitvity:  0.8961038961038962\n",
      "Specificity:  0.7391304347826088\n"
     ]
    }
   ],
   "source": [
    "# Write additional code here, if necessary (you may insert additional code cells)\n",
    "\n",
    "# calculate sensitivity and specificity\n",
    "tp = c_matrix.iloc[0,0]\n",
    "tn = c_matrix.iloc[1,1]\n",
    "fp = c_matrix.iloc[1,0]\n",
    "fn = c_matrix.iloc[0,1]\n",
    "\n",
    "sensitivity = (tp/len(y_pred))/(tp/len(y_pred)+fn/len(y_pred))\n",
    "specificity = (tn/len(y_pred))/(tn/len(y_pred)+fp/len(y_pred))\n",
    "\n",
    "print(\"Sensitvity: \", sensitivity)\n",
    "\n",
    "print(\"Specificity: \", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label \n",
       " <=50K    692\n",
       " >50K     208\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect counts of positive and negative labels in training se\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your text answer of 150-200 words in this cell.\n",
    "\n",
    "***Q1 Response**: The sensitivity of this model is 0.896 whilst specificity is 0.739. The difference is unsurprising as one measures the proportion of True Positive out of all the Actual Positives, whilst the other measures the proportion of True Negatives out of all the Actual Negatives (i.e. their numerator and denominator uses different statistics). A reason for sensitivity being higher could be that there are more than 3 times positively labelled attributes in the training set (692 to 208), and thus the model has better learnt how to predict positives.*\n",
    "\n",
    "*One way to improve model performance could be to use alternative methods to deal with \"?\" classes, either ignoring them in training or attempting to impute their value by comparing with similar training instances and imputing using their value for this attribute. This is expected to improve performance because whilst \"?\"'s true value is unknown to us, different instances containing \"?\" in the same attribute likely has different true underlying values, and thus bluntly grouping all into a new class may be an incorrect assumption that distorts the model.*\n",
    "\n",
    "*Another general suggestion is to collect more data, as more instances should help the model better learn the true behaviour.*\n",
    "\n",
    "\n",
    "**Word Count: 197**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 [4 marks]\n",
    "You can adopt different methods for training and/or testing, which will produce different results in model evaluation. \n",
    "\n",
    "(a) Instead of Gaussian, <u>implement KDE</u> for  $P(X_i|c_j)$ for numeric attributes $X_i$. Compare the evaluation results with Gaussian. Which one do you think is more suitable to model $P(X_i|c_j)$, Gaussian or KDE? Observe all numeric attributes and justify your answer.\n",
    "\n",
    "You can choose an arbitrary value for kernel bandwidth $\\sigma$ for KDE, but a value between 3 and 15 is recommended. You should write code to implement KDE, not call an existing function/method such as `KernelDensity` from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(a)\n",
    "\n",
    "# This function should calculates prior probabilities and likelihoods (conditional probabilities) from the training data\n",
    "# to build a naive Bayes model\n",
    "\n",
    "def train_kde(x_train, y_train):\n",
    "    \n",
    "    # prepare the data\n",
    "    train = x_train.copy()\n",
    "    train['label'] = y_train\n",
    "    \n",
    "    train_c1 = train[train['label'] == ' <=50K']\n",
    "    train_c2 = train[train['label'] == ' >50K']\n",
    "\n",
    "    # Create master dictionaries for each classe, which will: for prior and numerical attributes store tuples \n",
    "    # containing log likelihood / mean and standard deviation respectively, or for ordinal attributes store \n",
    "    # dictionaries which contain log observed probabilities of each value.\n",
    "    \n",
    "    # for each dictionary/tuple, it will be surrounded by a further tuple to denote its status as numerical \n",
    "    # attribute, ordinal attribute or prior.\n",
    "\n",
    "    c1_dict = dict()\n",
    "    c2_dict = dict()\n",
    "    \n",
    "    # store the log prior probabilities \n",
    "    c1_dict['prior'] = (np.log( len(train_c1) / len(train) ), 'prior')\n",
    "    c2_dict['prior'] = (np.log( len(train_c2) / len(train) ), 'prior')\n",
    "    \n",
    "    # iterate through the columns\n",
    "    for col in x_train.columns:\n",
    "        \n",
    "        # if find a column that is numeric\n",
    "        if col in NUMERIC_ATTRBS:\n",
    "            \n",
    "            # Prevent edge case of having '?' in numeric data which would cause np.mean and np.std to fail\n",
    "            # by putting all numeric data values into a new list.\n",
    "            tmp1 = list()\n",
    "            tmp2 = list()\n",
    "            \n",
    "            # comment same as train()\n",
    "            for i in train_c1[col].index:\n",
    "                if str(train_c1[col][i]).isnumeric():\n",
    "                    tmp1.append(int(train_c1[col][i]))\n",
    "            \n",
    "            for i in train_c2[col].index:\n",
    "                if str(train_c2[col][i]).isnumeric():\n",
    "                    tmp2.append(int(train_c2[col][i]))\n",
    "            \n",
    "            # This time for KDE just store whole list of numerical values into the tuple\n",
    "            c1_dict[col] = (tmp1, 'num')\n",
    "            c2_dict[col] = (tmp2, 'num')\n",
    "        \n",
    "        # if find a column that is nominal\n",
    "        else:\n",
    "            \n",
    "            # first find the set of all possible attribute values in the train set\n",
    "            attrb_val = set()\n",
    "            for val in train[col].value_counts().index:\n",
    "                attrb_val.add(val)\n",
    "            attrb_val = list(attrb_val)\n",
    "\n",
    "            \n",
    "            # for each value get its log observed probabilities (laplace smoothed alpha = 1)      \n",
    "            tmp1 = dict()\n",
    "            for i in range(len(train_c1[col].value_counts().index)):\n",
    "                # logic: dict[attrb value] = log( (counts_of_this_attribute_value + 1) / (n+p) ) \n",
    "                tmp1[train_c1[col].value_counts().index[i]] = np.log((train_c1[col].value_counts().values[i] + 1)/(len(train_c1)+len(attrb_val)))\n",
    "            \n",
    "            # for unseen attribute values that exist in train data but are of other class labels\n",
    "            for i in range(len(attrb_val)):\n",
    "                if attrb_val[i] not in train_c1[col].value_counts().index:\n",
    "                    # logic: dict[unseen attrb value] = log(1/(n+p))\n",
    "                    tmp1[attrb_val[i]] = np.log(1/(len(train_c1)+len(attrb_val)))\n",
    "                \n",
    "            c1_dict[col] = (tmp1, 'nom')\n",
    "               \n",
    "            tmp2 = dict()\n",
    "            for i in range(len(train_c2[col].value_counts().index)):\n",
    "                tmp2[train_c2[col].value_counts().index[i]] = np.log((train_c2[col].value_counts().values[i] + 1)/(len(train_c2)+len(attrb_val)))\n",
    "            \n",
    "            for i in range(len(attrb_val)):\n",
    "                if attrb_val[i] not in train_c2[col].value_counts().index:\n",
    "                    tmp2[attrb_val[i]] = np.log(1/(len(train_c2)+len(attrb_val)))\n",
    "                \n",
    "            c2_dict[col] = (tmp2, 'nom')\n",
    "            \n",
    "    \n",
    "    return c1_dict, c2_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict classes for new items in the testing data\n",
    "from scipy.stats import norm\n",
    "\n",
    "def predict_kde(x_test, c1_dict, c2_dict, STD):\n",
    "    \n",
    "    # re-index the test set\n",
    "    x_test.index = range(len(x_test))\n",
    "    \n",
    "    # create lists to store final predictions and class probabilities\n",
    "    y_pred = list()\n",
    "    c1_log_prob = list()\n",
    "    c2_log_prob = list()\n",
    "    \n",
    "    for i in range(len(x_test)): \n",
    "        c1 = 0     # sum of log probabilities for ' <=50' (i.e. log relative postier prob)\n",
    "        c2 = 0     # sum of log probabiliteis for ' >50' (i.e. log relative postier prob)\n",
    "         \n",
    "        # add the log prior probabilities\n",
    "        c1 += c1_dict['prior'][0]\n",
    "        c2 += c2_dict['prior'][0]\n",
    "        \n",
    "        for col in x_test.columns:\n",
    "            \n",
    "            if c1_dict[col][1] == 'num':\n",
    "                if str(x_test.loc[i][col]).isnumeric():\n",
    "                    \n",
    "                    kde_c1 = 0 # record sum(likelihoods based on KDE)\n",
    "                    for j in range(len(c1_dict[col][0])): # add the log likelihoods based on KDE built by train instance value\n",
    "                        kde_c1 += norm_pdf(float(x_test.loc[i][col]), c1_dict[col][0][j], STD) \n",
    "                    c1 += ( np.log(kde_c1) - np.log(len(c1_dict[col][0])) ) # log version of (1/N * sum(likelihoods based on KDE))\n",
    "\n",
    "                    kde_c2 = 0\n",
    "                    for j in range(len(c2_dict[col][0])):\n",
    "                        kde_c2 += norm_pdf(float(x_test.loc[i][col]), c2_dict[col][0][j], STD)\n",
    "                    c2 += ( np.log(kde_c2) - np.log(len(c2_dict[col][0])) )\n",
    "                \n",
    "                else: # Skip this numerical attribute for this instance if value is \"?\"\n",
    "                    pass   \n",
    "                \n",
    "            else:\n",
    "\n",
    "                if x_test.loc[i][col] in c1_dict[col][0]: \n",
    "                    # just comparing to the c1 prob set is enough because did laplace, so dict keys (unique attribute values) \n",
    "                    # should contain all training set unique attribute values\n",
    "                    c1 += c1_dict[col][0][x_test.loc[i][col]] # add log conditional probablity\n",
    "                    c2 += c2_dict[col][0][x_test.loc[i][col]]\n",
    "                    \n",
    "                else: # Skip this attribute for this instance if value has not been seen in training\n",
    "                    pass\n",
    "                         \n",
    "        c1_log_prob.append(c1)\n",
    "        c2_log_prob.append(c2)\n",
    "        \n",
    "        # record the appropriate prediction, based on the sum log probabilities of the two classes \n",
    "        # for this particular test instance\n",
    "        if c1 > c2:\n",
    "            y_pred.append(' <=50K')\n",
    "        elif c1 < c2:\n",
    "            y_pred.append(' >50K')\n",
    "        else: # if equal then randomly allocate based on distribution of prior\n",
    "            y_pred.append(random.choices([' <=50K', ' >50K'], weights = [np.exp(c1_dict['prior'][0]), 1-np.exp(c1_dict['prior'][0])])[0])\n",
    "            \n",
    "    return y_pred, c1_log_prob, c2_log_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "\n",
      "Confusion Matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred &lt;=50K</th>\n",
       "      <th>Pred &gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual &lt;=50K</th>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual &gt;50K</th>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Pred <=50K  Pred >50K\n",
       "Actual <=50K          68          9\n",
       "Actual >50K            6         17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1: 0.9006622516556292\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main function for KDE\n",
    "\n",
    "data = pd.read_csv('./dataset/adult.csv')\n",
    "\n",
    "x_train, x_test, y_train, y_test = preprocess(data)\n",
    "\n",
    "c1_dict_kde, c2_dict_kde = train_kde(x_train, y_train)\n",
    "\n",
    "y_pred_kde, c1_prob_kde, c2_prob_kde = predict_kde(x_test, c1_dict_kde, c2_dict_kde, STD = 3)\n",
    "\n",
    "accuracy_kde, c_matrix_kde, F1_kde = evaluate(y_pred_kde, y_test)\n",
    "\n",
    "# Second, print the full evaluation results from the evaluate() function\n",
    "print(\"Accuracy:\", accuracy_kde)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "display(c_matrix_kde)\n",
    "\n",
    "print(\"\\nF1:\", F1_kde)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['Accuracy', 'F1']\n",
    "two_fold = [accuracy, F1]\n",
    "ten_fold = [accuracy_kde, F1_kde]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, two_fold, width, label='Gaussian')\n",
    "rects2 = ax.bar(x + width/2, ten_fold, width, label='KDE')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Comparison of Gaussian and KDE')\n",
    "plt.xticks(x, labels, rotation = 0);\n",
    "plt.yticks([x/10 for x in range(13)])\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspection of numerical values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph age, education number, hours\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Age attribute distribution')\n",
    "plt.xlabel('Attribute Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(x_train['age'], bins = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Education Num attribute distribution')\n",
    "plt.xlabel('Attribute Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(x_train['education num'], bins = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Hours Per Week attribute distribution')\n",
    "plt.xlabel('Attribute Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(x_train['hours per week'], bins = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q2a Response**: Observing the evaluation statistics, Gaussian performs just slightly better than KDE in terms of both Accuracy and F1 for this set of training statistics.*\n",
    "\n",
    "*The distribution (observed from histograms) of the numerical attributes however point to a different direction: the ‘age’ attribute’s distribution is right-skewed, indicating that KDE should work better than Gaussian as it is non-symmetrical. The distribution of ‘education num’ is bimodal with peaks in 9-11 and 13-14, once again meaning KDE should work better as Gaussian assumes single mode. Finally, ‘hours per week’ has a single mode at 40-45 and thus should work better with Gaussian.*\n",
    "\n",
    "*Overall, with two numeric attributes pointing to KDE as the more suitable option, and Gaussian’s evaluation statistics only leading KDE marginally, KDE should be used rather than Gaussian.*\n",
    "\n",
    "*A better option would be to use KDE for ‘age’ and ‘education num’, and Gaussian for ‘hours per week’. This may require more inspection of data prior to training future model if more data arrives, and potentially causes issues for cross-validation; but assuming the training data generally captures the distribution of the whole set this shouldn’t be a problem, and would allow the model to utilise the best of both KDE and Gaussian.*\n",
    "\n",
    "**Word Count: 200**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Implement <u>10-fold and 2-fold cross-validations</u>.  \n",
    "\tObserve the evaluation results in each fold and the average accuracy, recall and specificity over all folds. \n",
    "\tComment on what is the effect by changing the values of $m$ in $m$-fold cross validation. (You can choose either Gaussian or KDE Naive Bayes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n",
    "# Write additional code here, if necessary (you may insert additional code cells)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "x = data[data.columns[:-1]]\n",
    "y = data[['label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "kf = KFold(n_splits = k, shuffle = False) # instantialise the KFold module\n",
    "\n",
    "# Create lists for storing desired values\n",
    "accuracy_score_2 = []\n",
    "specification_score_2 = []\n",
    "recall_score_2 = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    x_train, x_test = x.iloc[train_index, :], x.iloc[test_index, :]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    c1_dict, c2_dict = train(x_train, y_train)\n",
    "\n",
    "    y_pred, c1_prob, c2_prob = predict(x_test, c1_dict, c2_dict)\n",
    "\n",
    "    accuracy, c_matrix, F1 = evaluate(y_pred, y_test)\n",
    "    \n",
    "    # append the accuracy to the list\n",
    "    accuracy_score_2.append(accuracy)\n",
    "    \n",
    "    # regain the four measures from the matrix\n",
    "    tp = c_matrix.loc['Actual <=50K']['Pred <=50K']\n",
    "    tn = c_matrix.loc['Actual >50K']['Pred >50K']\n",
    "    fp = c_matrix.loc['Actual >50K']['Pred <=50K']\n",
    "    fn = c_matrix.loc['Actual <=50K']['Pred >50K']\n",
    "    \n",
    "    # calculate specification\n",
    "    specification = (tn/len(y_test)) / ( tn/len(y_test) + fp/len(y_test) )\n",
    "    specification_score_2.append(specification)\n",
    "     \n",
    "    # calculate recall    \n",
    "    recall = (tp/len(y_test)) / ( tp/len(y_test) + fn/len(y_test) )\n",
    "    recall_score_2.append(recall)\n",
    "\n",
    "# calculate mean scores out of all folds\n",
    "mean_accuracy_2 = np.mean(accuracy_score_2)\n",
    "mean_specification_2 = np.mean(specification_score_2)\n",
    "mean_recall_2 = np.mean(recall_score_2)                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "kf = KFold(n_splits = k, shuffle = False) # instantialise the KFold module\n",
    "\n",
    "# Create lists for storing desired values\n",
    "accuracy_score_10 = []\n",
    "specification_score_10 = []\n",
    "recall_score_10 = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    x_train, x_test = x.iloc[train_index, :], x.iloc[test_index, :]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    c1_dict, c2_dict = train(x_train, y_train)\n",
    "\n",
    "    y_pred, c1_log_prob, c2_log_prob = predict(x_test, c1_dict, c2_dict)\n",
    "\n",
    "    accuracy, c_matrix, F1 = evaluate(y_pred, y_test)\n",
    "    \n",
    "    # append the accuracy to the list\n",
    "    accuracy_score_10.append(accuracy)\n",
    "    \n",
    "    # regain the four measures from the matrix\n",
    "    tp = c_matrix.loc['Actual <=50K']['Pred <=50K']\n",
    "    tn = c_matrix.loc['Actual >50K']['Pred >50K']\n",
    "    fp = c_matrix.loc['Actual >50K']['Pred <=50K']\n",
    "    fn = c_matrix.loc['Actual <=50K']['Pred >50K']\n",
    "    \n",
    "    # calculate specification\n",
    "    specification = (tn/len(y_test)) / ( tn/len(y_test) + fp/len(y_test) )\n",
    "    specification_score_10.append(specification)\n",
    "     \n",
    "    # calculate recall    \n",
    "    recall = (tp/len(y_test)) / ( tp/len(y_test) + fn/len(y_test) )\n",
    "    recall_score_10.append(recall)\n",
    "\n",
    "# calculate mean scores out of all folds\n",
    "mean_accuracy_10 = np.mean(accuracy_score_10)\n",
    "mean_specification_10 = np.mean(specification_score_10)\n",
    "mean_recall_10 = np.mean(recall_score_10)                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy Score (2 fold):  0.821\n",
      "Average Recall Score (2 fold):  0.8596703058836263\n",
      "Average Specification Score (2 fold):  0.6939028048597571\n",
      "\n",
      "\n",
      "Average Accuracy Score (10 fold):  0.8150000000000001\n",
      "Average Recall Score (10 fold):  0.847512449866732\n",
      "Average Specification Score (10 fold):  0.7078850304285086\n"
     ]
    }
   ],
   "source": [
    "print('Average Accuracy Score (2 fold): ', mean_accuracy_2)\n",
    "print('Average Recall Score (2 fold): ', mean_recall_2)  \n",
    "print('Average Specification Score (2 fold): ', mean_specification_2)                                \n",
    "print('\\n')\n",
    "\n",
    "print('Average Accuracy Score (10 fold): ', mean_accuracy_10)\n",
    "print('Average Recall Score (10 fold): ', mean_recall_10) \n",
    "print('Average Specification Score (10 fold): ', mean_specification_10)                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['Avg Accuracy Score', 'Avg Recall Score', 'Avg Specification Score']\n",
    "two_fold = [mean_accuracy_2, mean_recall_2, mean_specification_2]\n",
    "ten_fold = [mean_accuracy_10, mean_recall_10, mean_specification_10]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, two_fold, width, label='2-fold')\n",
    "rects2 = ax.bar(x + width/2, ten_fold, width, label='10-fold')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Comparison between 2-fold and 10-fold')\n",
    "plt.xticks(x, labels, rotation = 0);\n",
    "plt.yticks([x/10 for x in range(11)])\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "**Q2b Response***: The Average Accuracy Score is 0.821 and 0.815 for 2-fold and 10-fold respectively; the Average Recall Score is 0.8596 and 0.8475 and the Average Specification Score is 0.6939 and 0.7078 respectively.*\n",
    "\n",
    "*For Average Accuracy and Recall Score, 2-fold has higher values than 10-fold; whilst for Average Specification Score, 10-fold has higher value than 2-fold. By the Central Limit Theorem, the mean scores of 10-fold should be closer to the true mean score of **this implementation of Naïve Bayes for this dataset**, and thus the 2-fold models are likely overfitting due to more randomness in the splits. Nonetheless, the differences are quite small.*\n",
    "\n",
    "*Another effect on changing the m parameter for m-fold cross validation (though not directly related to the scores), is the number of test cases are different. As cross validation requires all instances used once as a test case, 2-fold means 50% of the instances are used as test and 10-fold means 10% of the instances are used as tests. Using less folds does mean less data is being used for training and generally should make the model worse in terms of generalisability.*\n",
    "\n",
    "*Increasing m also increases computational time, as each fold needs to train one model.*\n",
    "\n",
    "\n",
    "**Word Count: 198**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 [4 marks]\n",
    "In `train()`, you are asked to treat the missing value of nominal attributes as a new category. There is another option (as suggested in Thu lecture in week 2): <u>ignoring the missing values</u>. \n",
    "Compare the two methods in both large and small datasets. Comment and explain your observations.\n",
    "You can extract the first 50 records to construct a small dataset.Use Gaussian Naive Bayes only for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write additional code here, if necessary (you may insert additional code cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your text answer of 150-200 words in this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 [4 marks]\n",
    "In week 4, we have learned how to obtain information gain (IG) and gain ratio (GR) to choose an attribute to split a node in a decision tree. We will see how to apply them in the Naive Bayes classification.\n",
    "\n",
    "(a) Compute the GR of each attribute $X_i$, relative to the class distribution. In the Na\\\"ive Bayes classifier, remove attributes in the ascending order of GR: first, remove $P(X_i|c_j)$ such that $X_i$ has the least GR; second, remove $P(X_{i'}|c_j)$ such that $X_{i'}$ has the second least GR,......, until there is only one $X_{i*}$ with the largest GR remaining in the maximand $P(c_j) P(X_{i^*} | c_j)$. Observe the <u>change of the accuracy for both Gaussian and KDE</u> (Choose bandwidth $\\sigma=10$ for KDE).\n",
    "\n",
    "(b) Compute the IG between each pair of attributes. Describe and explain your observations. Choose an attribute and implement an estimator to predict the value of `education num`. Explain why you choose this attribute. Enumerate two other examples that an attribute can be used to estimate the other and explain the reason.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write additional code here, if necessary (you may insert additional code cells)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your text answer to **Question 4.a** of 100-150 words in this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your text answer to **Question 4.b** of 150-200 words in this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Authorship Declaration</b>:\n",
    "\n",
    "   (1) I certify that the program contained in this submission is completely\n",
    "   my own individual work, except where explicitly noted by comments that\n",
    "   provide details otherwise.  I understand that work that has been developed\n",
    "   by another student, or by me in collaboration with other students,\n",
    "   or by non-students as a result of request, solicitation, or payment,\n",
    "   may not be submitted for assessment in this subject.  I understand that\n",
    "   submitting for assessment work developed by or in collaboration with\n",
    "   other students or non-students constitutes Academic Misconduct, and\n",
    "   may be penalized by mark deductions, or by other penalties determined\n",
    "   via the University of Melbourne Academic Honesty Policy, as described\n",
    "   at https://academicintegrity.unimelb.edu.au.\n",
    "\n",
    "   (2) I also certify that I have not provided a copy of this work in either\n",
    "   softcopy or hardcopy or any other form to any other student, and nor will\n",
    "   I do so until after the marks are released. I understand that providing\n",
    "   my work to other students, regardless of my intention or any undertakings\n",
    "   made to me by that other student, is also Academic Misconduct.\n",
    "\n",
    "   (3) I further understand that providing a copy of the assignment\n",
    "   specification to any form of code authoring or assignment tutoring\n",
    "   service, or drawing the attention of others to such services and code\n",
    "   that may have been made available via such a service, may be regarded\n",
    "   as Student General Misconduct (interfering with the teaching activities\n",
    "   of the University and/or inciting others to commit Academic Misconduct).\n",
    "   I understand that an allegation of Student General Misconduct may arise\n",
    "   regardless of whether or not I personally make use of such solutions\n",
    "   or sought benefit from such actions.\n",
    "\n",
    "   <b>Signed by</b>: Lang (Ron) Chen\n",
    "   \n",
    "   <b>Dated</b>: 7/4/2022"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
